---
title: 'Recitation 5: Graphics in R Using GGplot'
author: "Mohamed Shedeed"
date: "2023-02-21"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)
library(dplyr)
library(ggplot2)
library(car)
library(tidyverse)
```

# Review of R basics

Before we get into making visualizations, let's go over some basic principles of data exploration and analysis in R. 

## Looking at Data

We can get a glimpse of the data using the \verb|head| and \verb|str| functions. 

```{r}
dunc <- Duncan #I like to work with objects that start with lowercase letters
head(dunc) #take a look at the first few observations 
tail(dunc)
```

The \verb|head| function returns the first six observations in the data and the \verb|tail| function gives us the last six. Notice that we also see an unlabelled list of row names on the left. This type of data is somewhat uncommon, but does pop up once in a while. To get a more informative summary of the data, however, we can use the \verb|str| function.

```{r}
str(dunc)
```

This is helpful in gaining a better understanding of what our data looks like (although it doesn't provide us with the row names). We can see that our dataframe is comprised of 45 observations and 4 variables. We can also see the names and classes of each variables, along with a small number of their observations. \verb|str| also tells us the class of our object. Say we wanted to run \verb|str| on only one variable:

```{r}
str(dunc$type)
```

We get back the information for that variable that we originally saw when running \verb|str| on the whole dataframe. Now say we wanted to save that variable as a separate vector, then examine its structure. 

```{r}
d_type <- as.vector(dunc$type)
str(d_type)
```

We now see that \verb|d_type| is a character vector of length 45. 

If we want to look only at certain aspects of our dataframe, we can use some of the functions below, like \verb|colnames|, which returns the column or variable names, or \verb|class|, which returns the class of the object.

```{r}
colnames(dunc) # get column/ variable names
rownames(dunc)[1:5] #get rownames
class(dunc) #class of the data
```

Notice that I included the function \verb|rownames|. Because this dataframe has a label for each observations, this function returns a vector of those names. If we use another dataframe that does not have that attribute, R returns a vector of observation indices.

```{r}
rownames(iris)[1:5]
```

Now say we wanted to apply a certain function over each element in our data. We can use the \verb|apply| family of functions to do this. 

```{r}
lapply(dunc, class) 
sapply(dunc, class) 
```

Notice that \verb|lapply| and \verb|sapply| provide us with the same information. So what's the difference? 

```{r}
class(lapply(dunc, class)) #you can also check the class of code output 
class(sapply(dunc, class))
```

By using the \verb|class| function on on output, we can see that \verb|lapply| will always return a list. \verb|sapply|, on the other hand, will try to condense its output into a simpler object. In this case, it returns a vector because each element in its output has a length of 1. But what happens when we ask \verb|sapply| to give us more complicated output? 

```{r}
sapply(dunc, str)
class(sapply(dunc, str))
```

Because we're using the \verb|str| function on each of these objects, R returns a list as its output. This is a pretty inefficient way of doing things, since we could just run \verb|str| on the whole dataframe instead, but it's a helpful way to understand the differences between \verb|lapply| and \verb|sapply|. 

## Seeds

Notice that I use the \verb|set.seed| function. Setting your seed is absolutely necessary in \verb|R| and any other programming language. Seeds are essentially the way that computer "randomly" generate numbers. This is why simulated data in \verb|R| is pseudo-random. If you set a seed, generate a list of values from a distribution, and repeat both of those steps 100 times, you'll get the same output each time. If you set your seed and generate those values 100 times without re-setting your seed, you'll get 100 different outputs. But, if you did \textit{that} 100 times, you would get the same set of 100 randomly generated distributions. Let me show you what I mean, using a smaller sample size.

I'll set my seed, generate three numbers from a Standard Normal distribution, then repeat both of those steps. 

```{r}
set.seed(123)
rnorm(3, 0, 1)

set.seed(123)
rnorm(3, 0, 1)
```

If we do this, we get the exact same values both times. But if we do not re-set our seed:

```{r}
set.seed(123)
rnorm(3, 0, 1)
rnorm(3, 0, 1)
```

we get a different set of values. The decision to re-set your seed depends on what you're doing. If you want to generate a variety of samples (see the tutorial on sampling distributions), you won't need to re-set your seed. However, if you're performing $k$-fold cross-validation (see tutorial on regression) on two different models, you may want to re-set your seed to ensure that both models are being tested using the same data folds. 

Setting your seed is essential to ensuring that your work is replicable, meaning that if you send your code with randomly generated data to someone else, they can run it and obtain the exact same results you did. 

## Using tidyverse

Now we can move on to using \verb|tidyverse|. I'll go step by step to show how \verb|tidyverse| can streamline some things in R and make your life a whole lot easier. Loading \verb|tidyverse| will install a few useful packages, such as \verb|dplyr|, which we'll use below, and \verb|ggplot2|, which I'll cover in a separate tutorial. 

First, I'll go over the general syntax of dplyr. These functions generally take the dataframe as the first argument and the action as the second. For example, using the \verb|mutate| function below allows us to create a new variable in \verb|dunc|. Let's create a new variable taken from a Bernoulli distribution using $p=0.5$. We can use \verb(names) to confirm the new variable was created. We're going to be creating a new dataset here so that we keep one clean copy of the data. 

```{r}
set.seed(123)
dunc2 <- mutate(dunc, extravar = rbinom(nrow(dunc), 1, 0.5))
names(dunc2)
```

Now say we wanted to set a conditional probability on the value of our new variable. For those observations with an education score of $84$ or above, we want to regenerate the values of this variable using a probability of $0.75$, with a probability of $0.5$ otherwise. Then, we want to use the \verb|summarise| function to find the empirical probability of \verb|extravar| $=1$ given that \verb|education| $>84$. 

```{r}
dunc2 <- mutate(dunc, extravar = rbinom(nrow(dunc), 1, p = ifelse(education > 84, 0.75, 0.5)))
summarise(dunc2, newdist = mean(dunc2$extravar[dunc2$education > 84]))
```

That's a pretty inefficient way of doing things. We had to subset the data within the \verb|summarise| function, and we needed to specify our dataframe in each line. Using the pipe operator %>% allows us to do this faster and make our code a little easier to read. Let's see how this works:

```{r}
set.seed(123)
dunc2 <- dunc %>% 
  mutate(extravar = rbinom(nrow(dunc), 1, p = ifelse(education > 84, 0.75, 0.5))) 

dunc2 %>% 
  filter(education > 84) %>% 
  summarise(newdist = mean(extravar))
```

Using the %>% operator makes writing and reading code much easier, and reduces the risk of human error. In the next tutorial, I'll be going over how to visualize this data using \verb|ggplot2|. In another tutorial, I'll show you how to use \verb|dplyr| to clean and analyze data. 

```{r}
dunc2 %>% 
  ggplot() + 
  geom_point(aes(x = income, y = prestige, color = as.factor(extravar)))
```

There's loads of other stuff you can use the tidy environment for, but we'll cover that in later lab sessions.

# GGplot

GGplot uses something called "grammar of graphics" to make plots in R. It is often preferred over base R plots due to its aesthetic appeal. You can edit plots easily, add layers, and organize your plots in any way you wish. You can also easily adapt the ggplot environment for dot-whisker plots and even confusion matrices. 

Let's get started plotting some basic data.


```{r}
ggplot(dunc, aes(x = income, y = prestige)) +
  geom_point()
```

We can combine what we know about ggplot and the tidverse to streamline our code using the %>% operator.

```{r}
dunc %>% 
  ggplot(aes(x = income, y = prestige)) + 
  geom_point()
```

But what if we want to plot two variables? Well, we can add another layer. But this time, try to notice what else I'm changing about the code. 

```{r}
dunc %>% 
  ggplot() +
  geom_point(aes(x = income, y = prestige)) +
  geom_point(aes(x = education, y = prestige), color = "blue")
```

Okay, so now we have a basic plot, but we're missing a bunch of things. If we're happy with this skeleton, we can save it as an object and add additional layers to make it more presentable.

```{r}
p <- dunc %>% 
  ggplot() +
  geom_point(aes(x = income, y = prestige, color = income),
             shape = 18,
             color = "darkred") +
  geom_point(aes(x = education, y = prestige, color = education), 
             color = "darkblue",
             shape = 25)

p <- p + labs(title = "Prestige by Income",
         x = "Income and Education",
         y = "Presitge",
         caption = "There's a typo in the y-axis label")
```

Let's keep going. What else can we do to this plot?

```{r}
p <- p + 
  theme_bw() + #change the theme 
  scale_x_continuous(labels = scales::dollar) + #add dollar signs 
  geom_smooth(method = "lm", formula = "y ~ x", aes(x = income, y = prestige), se = FALSE,
              color = "darkred") +
  geom_smooth(method = "loess", formula = "y ~ x", aes(x = education, y = prestige), se = FALSE,
              color = "darkblue")
  
```

Note: LOESS is a type of localized regression. We don't cover those in this class, but localized regressions and other adaptions of the linear model like cubic splines are really interesting and widely used in econometrics.

We can do more like change font size

```{r}
p + theme(text = element_text(size = 20)) 
```

Or change just the axes

```{r}
p + theme(axis.text = element_text(size = 20))

p + theme(axis.text.x = element_text(size = 20))

p + theme(axis.text.y = element_text(size = 20))

p + theme(axis.title = element_text(size = 20))

p + theme(axis.title.x = element_text(size = 20))

p + theme(axis.title.y = element_text(size = 20))
```

Lastly, we can change the title size.

```{r}
p + theme(plot.title = element_text(size = 20))
```

You can also use ggplot to display distributions

```{r}
p <- dunc %>% 
  ggplot(aes(x = education)) +
  geom_histogram(aes(y = ..density..),
                 fill = "grey",
                 colour = "darkred")
```

And add titles, labels, etc. like before

```{r}
p <- p +
  labs(title = "Distribution of Education",
       x = "Education",
       y = "Density") +
  geom_density(lwd = 1,
               colour = "darkred",
               fill = "grey",
               alpha = 0.25)
```

We can also add some points of summary stats

```{r}
p <- p + geom_vline(xintercept = mean(dunc$education),
               linetype = "dashed",
                color = "green") +
  geom_vline(xintercept = median(dunc$income),
               linetype = "dashed",
               color = "blue")
```

Let's look at a slightly more complicated example

```{r}
p <- dunc %>% 
  ggplot(aes(x = as.factor(type),
             y = education)) +
  geom_boxplot() +
  labs(title = "Distribution of Education by Job Type",
       x = "Job Type",
       y = "Education") +
  scale_x_discrete(labels = c("BC", "Prof.", "WC")) # we can use this layer to change axis labels
```

This one shows distributions of education conditional on type. Boxplots certainly have some advantages over histograms in that they easily provide summaries of the data. But, we lose the ability to easily visualize the distribution. We can solve this by adding an additional layer - violin plots. 

```{r}
p + geom_violin()
```

This is a bit clunky. What can we do to fix it up?

```{r}
p <- dunc %>% 
  ggplot(aes(x = as.factor(type),
             y = education)) +
  geom_violin(aes(color = as.factor(type))) +
  geom_boxplot(width = 0.2) +
  labs(title = "Distribution of Education by Job Type",
       x = "",
       y = "Education",
       color = "Job Type") +
  scale_x_discrete(labels = c()) + # we can use this layer to change axis labels
  theme(axis.ticks.x = element_blank()) +
  scale_color_discrete(labels = c("BC",
                                 "Prof.",
                                 "WC")) #why did we use scale_color and not scale_fill?
```

Want to move the legend around?

```{r}
#You can put it in the bottom
p + theme(legend.position = "bottom")

# On the top
p + theme(legend.position = "top")

# Inside the plot
p + theme(legend.position = c(0.9, 0.1))

# Even in the most inappropriate place imagineable 
p + theme(legend.position = c(0.5, 0.7))

# The bottom is probably the best spot for it here
p + theme(legend.position = "bottom")
```


# Using ggplot for logistic regression 

Now we can apply these methods to plotting probability curves and dot-whisker plots.

Let's make up some data 

```{r, message=FALSE, warning=FALSE}
library(data.table)
n <- 1000
dat <- data.table(x = rnorm(n),
                  z = rnorm(n, 5, 8),
                  f = rpois(n, 9),
                  r = rexp(n, 3))
summary(dat$x)
dat[x > median(x), d := rbinom(nrow(dat[x > median(x)]), 1, 0.85)][
  x < median(x) & f < median(f), d := rbinom(nrow(dat[x < median(x) & f < median(f), ]), 1, 0.1)
][
  x < median(x) & f > median(f), d := rbinom(nrow(dat[x < median(x) & f > median(f), ]), 1, 0.3)
]
```

```{r, message=FALSE, warning=FALSE}
logmod1 <- glm(d ~ x + z + r, dat, family = "binomial")
summary(logmod1)

logmod2 <- glm(d ~ x + z + f + r, dat, family = "binomial")
summary(logmod2)
```

We can use a new package to make some nice coefficient plots. But it takes some cleaning. 

```{r, message=FALSE, warning=FALSE}
library(broom)
library(dotwhisker)
```

```{r}
log1_df <- broom::tidy(logmod1) %>% mutate(model = "Without f")
log2_df <- broom::tidy(logmod2) %>% mutate(model = "With f")

mods <- rbind(log1_df, log2_df)

dwplot(mods,
       model_name = "model") 
```

But again, this looks pretty horrible. Let's fix that

```{r}
dwplot(mods,
       model_name = "model") %>% 
  relabel_predictors(c(
    x = "X",
    z = "Z",
    r = "R",
    f = "F"
  )) +
  labs(title = "Model Results",
       color = "Model",
       x = expression(paste(beta, " estimates")),
       y = "Predictor") +
  theme_bw() + 
  geom_vline(xintercept = 0,
             linetype = "dashed",
             alpha = 0.5)
```

Let's say we wanted to plot predicted probabilites across values of x. 

There are two ways to do this. First, If we wanted to just plot the bivariate relationship, we could use

```{r}
dat %>% 
  ggplot(aes(x = x, y = d)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "glm",
              se = FALSE,
              method.args = list(family = binomial))
```

If we want to take the predicted probabilities using the function we created above, we can do that to. 

After fitting our model, we can extract the fitted probs.

```{r}
fits <- broom::augment(logmod2, type.predict = "response") %>% 
  mutate(d1 = ifelse(d == 1, x, NA),
         d0 = ifelse(d == 0, x, NA))

fits %>% 
  ggplot(aes(x = x)) +
  geom_line(aes(y = .fitted)) +
  geom_rug(aes(x = d0), sides = "b", alpha = 0.2) +
  geom_rug(aes(x = d1), sides = "t", alpha = 0.2) +
  labs(title = "Predicted Probabilities by value of X",
       x = "X",
       y = "Predicted Probability")
```

How would this change if we plotted the probabilities from the other model?

```{r}
fits <- broom::augment(logmod1, type.predict = "response") %>% 
  mutate(d1 = ifelse(d == 1, x, NA),
         d0 = ifelse(d == 0, x, NA))

fits %>% 
  ggplot(aes(x = x)) +
  geom_line(aes(y = .fitted)) +
  geom_rug(aes(x = d0), sides = "b", alpha = 0.2) +
  geom_rug(aes(x = d1), sides = "t", alpha = 0.2) +
  labs(title = "Predicted Probabilities by value of X",
       x = "X",
       y = "Predicted Probability")
```

# Presenting Regression Results

Let's make a publication quality table using the texreg package. 

To use the Duncan data we used before, we can create a new dummy variable for individuals who are in the higher end of distribution of prestige. 

```{r, warning=FALSE, message=FALSE}
library(texreg)
dunc <- mutate(dunc, high_pres = prestige > quantile(dunc$prestige, 0.5))
```

Then run a logistic regression

```{r, results=FALSE}
logit1 <- glm(high_pres ~ income + education, dunc, family = "binomial")

summary(logit1)
```

We can use texreg to put this into \LaTeX code. To do so, copy the R output starting from where it says \verb|\begin{table}| and paste it into the empty space in Rmarkdown. 

```{r, include = FALSE}
texreg(logit1)
```

\begin{table}
\begin{center}
\begin{tabular}{l c}
\hline
 & Model 1 \\
\hline
(Intercept)    & $-5.93^{***}$ \\
               & $(1.77)$      \\
income         & $0.06^{*}$    \\
               & $(0.03)$      \\
education      & $0.06^{**}$   \\
               & $(0.02)$      \\
\hline
AIC            & $31.71$       \\
BIC            & $37.13$       \\
Log Likelihood & $-12.86$      \\
Deviance       & $25.71$       \\
Num. obs.      & $45$          \\
\hline
\multicolumn{2}{l}{\scriptsize{$^{***}p<0.001$; $^{**}p<0.01$; $^{*}p<0.05$}}
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}

This table isn't very nice. We can change that

```{r, results=FALSE}
texreg(logit1,
       stars = numeric(),
       bold = 0.05,
       custom.coef.names = c("Constant", "Income",
                             "Education"),
       custom.model.names = "Basic Logit")
```

\begin{table}
\begin{center}
\begin{tabular}{l c}
\hline
 & Basic Logit \\
\hline
Constant       & $\mathbf{-5.93}$ \\
               & $(1.77)$         \\
Income         & $\mathbf{0.06}$  \\
               & $(0.03)$         \\
Education      & $\mathbf{0.06}$  \\
               & $(0.02)$         \\
\hline
AIC            & $31.71$          \\
BIC            & $37.13$          \\
Log Likelihood & $-12.86$         \\
Deviance       & $25.71$          \\
Num. obs.      & $45$             \\
\hline
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}

Much better. Let's do this with another model, this time adding type into the model.

```{r}
logit2 <- glm(high_pres ~ income + type + education, dunc, family = "binomial")
```

```{r, results=FALSE}
texreg(list(logit1, logit2),
       stars = numeric(),
       bold = 0.05,
       custom.coef.names = c("Constant", "Income",
                             "Education",
                              "Type (Prof)",
                             "Type (WC)"),
       custom.model.names = c("Basic Logit", "Other Logit"))
```

\begin{table}
\begin{center}
\begin{tabular}{l c c}
\hline
 & Basic Logit & Other Logit \\
\hline
Constant       & $\mathbf{-5.93}$ & $-13.94$    \\
               & $(1.77)$         & $(8.68)$    \\
Income         & $\mathbf{0.06}$  & $0.22$      \\
               & $(0.03)$         & $(0.17)$    \\
Education      & $\mathbf{0.06}$  & $0.14$      \\
               & $(0.02)$         & $(0.09)$    \\
Type (Prof)    &                  & $17.09$     \\
               &                  & $(4924.72)$ \\
Type (WX)      &                  & $-10.52$    \\
               &                  & $(6.95)$    \\
\hline
AIC            & $31.71$          & $17.05$     \\
BIC            & $37.13$          & $26.09$     \\
Log Likelihood & $-12.86$         & $-3.53$     \\
Deviance       & $25.71$          & $7.05$      \\
Num. obs.      & $45$             & $45$        \\
\hline
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}

Notice that we had to add two additional coefficient names instead of one. Why?

Now, say we wanted to hide the coefficients for type. Sometimes you might want to do this if you're using fixed effects. 

```{r, results=FALSE}
texreg(list(logit1, logit2),
       stars = numeric(),
       bold = 0.05,
       custom.coef.names = c("Constant", "Income",
                             "Education",
                              "Type (Prof)",
                             "Type (WC)"),
       custom.model.names = c("Basic Logit", "Other Logit"),
       omit.coef = "type")
```

\begin{table}
\begin{center}
\begin{tabular}{l c c}
\hline
 & Basic Logit & Other Logit \\
\hline
Constant       & $\mathbf{-5.93}$ & $-13.94$ \\
               & $(1.77)$         & $(8.68)$ \\
Income         & $\mathbf{0.06}$  & $0.22$   \\
               & $(0.03)$         & $(0.17)$ \\
Education      & $\mathbf{0.06}$  & $0.14$   \\
               & $(0.02)$         & $(0.09)$ \\
\hline
AIC            & $31.71$          & $17.05$  \\
BIC            & $37.13$          & $26.09$  \\
Log Likelihood & $-12.86$         & $-3.53$  \\
Deviance       & $25.71$          & $7.05$   \\
Num. obs.      & $45$             & $45$     \\
\hline
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}






















